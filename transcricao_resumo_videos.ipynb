{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3MLuFhHBpOr"
      },
      "source": [
        "# Transcrição e compreensão de vídeos do YouTube\n",
        "\n",
        "**Descrição:**\n",
        "\n",
        "Este projeto permite a transcrição automática e análise de conteúdo de vídeos do YouTube. Com ele, é possível obter informações detalhadas sobre um vídeo sem precisar assisti-lo por completo. O sistema combina APIs de transcrição com modelos de linguagem (LLMs) para sumarização e análise de conteúdo.\n",
        "\n",
        "\n",
        "**Funcionalidades:**\n",
        "\n",
        "- **Transcrição de vídeos do YouTube**: Obtém legendas automáticas através da API YouTube Transcript.\n",
        "- **Extração de metadados**: Coleta informações como título, autor e data de publicação via yt-dlp.\n",
        "- **Resumo e análise**: Utiliza modelos de IA para sumarizar e listar os principais temas do vídeo.\n",
        "- **Personalização de consultas**: Permite fazer perguntas específicas sobre o conteúdo do vídeo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ficha Técnica\n",
        "\n",
        "| 🔍 **Item**          | 📄 **Descrição** |\n",
        "|----------------------|----------------------------|\n",
        "| **🛠 Tecnologias**  | Python, LangChain, Hugging Face, OpenAI, Ollama |\n",
        "| **📦 Dependências** | youtube-transcript-api, yt-dlp, transformers, langchain, openai |\n",
        "| **⚙️ Funcionalidade** | Transcrição, sumarização e análise de vídeos do YouTube |\n",
        "| **📌 Modelos Utilizados** | Meta-Llama-3-8B-Instruct, GPT-4o-mini, Phi-3 |\n",
        "| **🎯 Entrada** | URL de um vídeo do YouTube |\n",
        "| **📊 Saída** | Transcrição, resumo e análise dos temas abordados no vídeo |\n",
        "| **🔑 Autenticação** | Token da Hugging Face e OpenAI (quando aplicável) |"
      ],
      "metadata": {
        "id": "bAyiKpiDdxDN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ9gpWgBDV7y"
      },
      "source": [
        "## Instalação e Configuração"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -q langchain_core langchain_community langchain-huggingface langchain_ollama langchain_openai\n",
        "!pip install -q langchain_core==0.3.32 langchain_community==0.3.15 langchain-huggingface langchain_ollama langchain_openai"
      ],
      "metadata": {
        "id": "Xzc8u4SnL5Io",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bacc9d6-cea5-4404-cf17-115661d87837"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m680.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.4/412.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSLHzeWUt-S2"
      },
      "source": [
        "### Instalação de bibliotecas para baixar transcrição:\n",
        "-  **YouTube Transcript API**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBMK_nzjMXzr",
        "outputId": "bec6582c-5ab1-4c6e-a94a-1a13ec8e6d0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m1.5/2.2 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlGwCqzdvHfy"
      },
      "source": [
        "-  **Pytube**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube #recuperar outras infos do video: titulo, data de publicacao, descricao etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z3a89t8MhFQ",
        "outputId": "f58c7102-ce18-4974-f14d-8e7776dbaf6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raKvr8oow-yL"
      },
      "source": [
        "## Importações"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import getpass\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "0KsvbMvhMv2x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0DTTSc_t7vA"
      },
      "source": [
        "## Carregando a transcrição e fazendo a leitura\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#solucão bem-sucedida\n",
        "\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def get_transcricao(video_url):\n",
        "    try:\n",
        "        video_id = video_url.split(\"v=\")[-1]  # Extrai o ID do vídeo da URL\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"pt\", \"pt-BR\", \"en\"])\n",
        "        transcricao = \" \".join([snippet[\"text\"] for snippet in transcript])\n",
        "        return transcricao\n",
        "    except Exception as e:\n",
        "        return f\"Erro ao obter transcrição: {e}\"\n",
        "\n",
        "# Teste com um vídeo do YouTube\n",
        "video_url = \"https://www.youtube.com/watch?v=II28i__Tf3M\"\n",
        "transcricao = get_transcricao(video_url)\n",
        "print(\"Transcrição do vídeo:\\n\", transcricao)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h04qgM8MDPul",
        "outputId": "bf81cdd0-0481-4da9-bc82-2278d35d2469"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcrição do vídeo:\n",
            " Olá sejam bem-vindos a sala que você vai aprender alguns fundamentos biológicos básicos sobre as redes neurais Primeiramente você verá sobre as redes neurais humana na sequência Vamos trabalhar com as redes neurais artificiais nós temos essa imagem representa os neurônios do cérebro existem bilhões de neurônios que estão conectados base nesta imagem nós vamos discutir três principais o primeiro ponto é que existem muitos neurônios o segundo ponto é que eles estão conectados entre si e o terceiro ponto é que estes neurônio por meio dessas conexões trocam informações entre si conexão entre os neurônios dos é e é responsável pelas nossas habilidades por exemplo ver falar dar e assim por diante vamos supor que você fala o idioma português e se indica que essas conexões entre os neurônios estão criadas de forma a permitir você falar esse idioma vamos supor que você começa a aprender a falar inglês com isso novas conexões Entre esses neurônios são geradas para permitir que você consiga falar esse idioma a troca de informação entre os neurônios e permite que você aprenda novas habilidades essa é uma imagem geral que mostra essa conexão entre os neurônios vamos agora analisar neurônios of e pode ser considerado cada um desses elementos maiores com os núcleos e existem alguns componentes primeiro componente e o neurônio são os dendritos ou seja são esses terminais que recebem informações na sequência nós temos o corpo ou celular que é aqui dentro que ocorre o processamento da informação mas temos o axónio que vai transmitir essa informação processada até essa calda do neurônio que é chamado dos terminais do axónio os dados entram pelos dendritos são processados no corpo celular e são enviados para o próximo neurônio por meio dos terminais do AXN nós podemos observar essa outra figura com o neurônio um pouco menor e uma rede neural nada mais é do que a conexão entre vários neurônios perceba que por meio da ligação dos terminais do axónio com os dendritos ocorre a troca de informação entre esses dois neurônios podemos adicionar mais um neurônio mais um mais um e definimos vários outros neurônios com isso mas temos a definição da rede neural completa que simula essa imagem perceba que Agora fica mais fácil para nós observar nos componentes do neurônio a informação chega pelos dendritos é processado no corpo celular e é enviada para os outros neurônios por mim os terminais do axônio e essa conexão o a troca de informações entre os neurônios é chamada de sinapse e no cérebro humano são representadas por processos elétricos Ou seja quando uma informação é passada de neurônio para o outro o potencial elétrico do corpo celular do neurônio é alterado esses que são os principais conceitos biológicos resumido sobre as redes neurais e na próxima aula você vai entender como funcionam os neurônios artificiais obrigado e até lá\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "📝 NOTA: **Defininido idiomas**\n",
        "- A função language espera uma lista em prioridade decrescente (por padrão). A grande maioria dos vídeos testados possuem legenda com código \"pt\", mesmo para vídeos com a legenda em português brasileiro. Para os outros colocamos \"pt-BR\"."
      ],
      "metadata": {
        "id": "p0d8QkR9WZKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obter informações do vídeo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "anF9L80yUejl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79UEeIZCJRNM",
        "outputId": "7c61ede0-b95a-41e6-d1a4-1920b782c812"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.3.27-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m163.8/172.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.3.27-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.3.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp\n",
        "\n",
        "def get_video_info_yt_dlp(video_url):\n",
        "    try:\n",
        "        ydl_opts = {\"quiet\": True}\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(video_url, download=False)\n",
        "\n",
        "        video_info = {\n",
        "            \"Título\": info.get(\"title\", \"Desconhecido\"),\n",
        "            \"Autor\": info.get(\"uploader\", \"Desconhecido\"),\n",
        "            \"Data de Publicação\": info.get(\"upload_date\", \"Desconhecida\"),\n",
        "            \"URL\": video_url\n",
        "        }\n",
        "        return video_info\n",
        "    except Exception as e:\n",
        "        return {\"Erro\": str(e)}\n",
        "\n",
        "# Teste com um vídeo do YouTube\n",
        "video_url = \"https://www.youtube.com/watch?v=II28i__Tf3M\"\n",
        "video_info = get_video_info_yt_dlp(video_url)\n",
        "print(video_info)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eff-GugLKQNp",
        "outputId": "f8edfa8e-9bb4-4a96-a6e3-524411db02f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Título': 'Introdução aos fundamentos biológicos das redes neurais artificiais', 'Autor': 'IA Expert Academy', 'Data de Publicação': '20220329', 'URL': 'https://www.youtube.com/watch?v=II28i__Tf3M'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reunindo as informações do vídeo + transcrição"
      ],
      "metadata": {
        "id": "XyhrP9KeRIUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOVO FORMATO\n",
        "# Obtendo metadados e transcrição do vídeo\n",
        "video_info = get_video_info_yt_dlp(video_url)\n",
        "transcricao = get_transcricao(video_url)\n",
        "\n",
        "# Formatando as informações do vídeo\n",
        "infos_video = f\"\"\"Informações do Vídeo:\n",
        "\n",
        "Título: {video_info[\"Título\"]}\n",
        "Autor: {video_info[\"Autor\"]}\n",
        "Data de Publicação: {video_info[\"Data de Publicação\"]}\n",
        "URL: {video_info[\"URL\"]}\n",
        "\n",
        "Transcrição:\n",
        "{transcricao}\n",
        "\"\"\"\n",
        "\n",
        "print(infos_video)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7X-wsK0LTX0",
        "outputId": "398359d6-5109-4b0f-8c1e-398e05ad64b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Informações do Vídeo:\n",
            "\n",
            "Título: Introdução aos fundamentos biológicos das redes neurais artificiais\n",
            "Autor: IA Expert Academy\n",
            "Data de Publicação: 20220329\n",
            "URL: https://www.youtube.com/watch?v=II28i__Tf3M\n",
            "\n",
            "Transcrição:\n",
            "Olá sejam bem-vindos a sala que você vai aprender alguns fundamentos biológicos básicos sobre as redes neurais Primeiramente você verá sobre as redes neurais humana na sequência Vamos trabalhar com as redes neurais artificiais nós temos essa imagem representa os neurônios do cérebro existem bilhões de neurônios que estão conectados base nesta imagem nós vamos discutir três principais o primeiro ponto é que existem muitos neurônios o segundo ponto é que eles estão conectados entre si e o terceiro ponto é que estes neurônio por meio dessas conexões trocam informações entre si conexão entre os neurônios dos é e é responsável pelas nossas habilidades por exemplo ver falar dar e assim por diante vamos supor que você fala o idioma português e se indica que essas conexões entre os neurônios estão criadas de forma a permitir você falar esse idioma vamos supor que você começa a aprender a falar inglês com isso novas conexões Entre esses neurônios são geradas para permitir que você consiga falar esse idioma a troca de informação entre os neurônios e permite que você aprenda novas habilidades essa é uma imagem geral que mostra essa conexão entre os neurônios vamos agora analisar neurônios of e pode ser considerado cada um desses elementos maiores com os núcleos e existem alguns componentes primeiro componente e o neurônio são os dendritos ou seja são esses terminais que recebem informações na sequência nós temos o corpo ou celular que é aqui dentro que ocorre o processamento da informação mas temos o axónio que vai transmitir essa informação processada até essa calda do neurônio que é chamado dos terminais do axónio os dados entram pelos dendritos são processados no corpo celular e são enviados para o próximo neurônio por meio dos terminais do AXN nós podemos observar essa outra figura com o neurônio um pouco menor e uma rede neural nada mais é do que a conexão entre vários neurônios perceba que por meio da ligação dos terminais do axónio com os dendritos ocorre a troca de informação entre esses dois neurônios podemos adicionar mais um neurônio mais um mais um e definimos vários outros neurônios com isso mas temos a definição da rede neural completa que simula essa imagem perceba que Agora fica mais fácil para nós observar nos componentes do neurônio a informação chega pelos dendritos é processado no corpo celular e é enviada para os outros neurônios por mim os terminais do axônio e essa conexão o a troca de informações entre os neurônios é chamada de sinapse e no cérebro humano são representadas por processos elétricos Ou seja quando uma informação é passada de neurônio para o outro o potencial elétrico do corpo celular do neurônio é alterado esses que são os principais conceitos biológicos resumido sobre as redes neurais e na próxima aula você vai entender como funcionam os neurônios artificiais obrigado e até lá\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evbo5__itytT"
      },
      "source": [
        "## Salvando transcrição em um arquivo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando a transcrição e as informações do vídeo em um arquivo\n",
        "with io.open(\"transcricao.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(infos_video)  # Agora escrevemos diretamente o conteúdo formatado na variável infos_video\n"
      ],
      "metadata": {
        "id": "I75djtOlLvkK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsIUtB4k0EOr"
      },
      "source": [
        "## Carregamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo do HuggingFace (Llama3)"
      ],
      "metadata": {
        "id": "1n95ERuc9TS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "def model_hf_hub(model = \"meta-llama/Meta-Llama-3-8B-Instruct\", temperature = 0.1):\n",
        "  llm = HuggingFaceEndpoint(repo_id = model,\n",
        "                       temperature = temperature,\n",
        "                       return_full_text = False,\n",
        "                       max_new_tokens = 1024,\n",
        "                       task=\"text-generation\"\n",
        "                       )\n",
        "  return llm"
      ],
      "metadata": {
        "id": "Tz96zelri2Ip"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo da OpenAI (pago)"
      ],
      "metadata": {
        "id": "OsvYpccU9Xhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_openai(model = \"gpt-4o-mini\", temperature = 0.1):\n",
        "  llm = ChatOpenAI(model = model, temperature = temperature)\n",
        "  return llm"
      ],
      "metadata": {
        "id": "4qrY-5X2jasE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo Ollama (phi3)"
      ],
      "metadata": {
        "id": "2H-HVWet9Z7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_ollama(model = \"phi3\", temperature = 0.1):\n",
        "  llm = ChatOllama(model = model, temperature = temperature)\n",
        "  return llm"
      ],
      "metadata": {
        "id": "-8B7J4L2joZ6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir o token do Hugging Face"
      ],
      "metadata": {
        "id": "A43x9uhLgIpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass()\n",
        "os.environ[\"HF_TOKEN\"] = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtbMrdU1j5YM",
        "outputId": "793f69de-c1a1-4c07-bfd0-ba8cc97b7d24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir o token da OpenAI"
      ],
      "metadata": {
        "id": "OkMqBYOweNcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "VysW6-CTkDP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIBmX2hrz3JT"
      },
      "source": [
        "## Junção da pipeline em funções\n",
        "\n",
        "para evitar repetições do código vou reunir toda a lógica em funções"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_chain(model_class):\n",
        "    system_prompt = \"\"\"\n",
        "    Você é um assistente virtual muito detalhista. Sua tarefa é fornecer respostas claras e diretas com base na transcrição de um vídeo. Quando solicitado, deve ser capaz de resumir o conteúdo ou listar temas específicos. Utilize o idioma português.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt_template = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        (\"user\", \"Consulta: {consulta} \\n Transcrição: {transcricao}\")\n",
        "    ])\n",
        "\n",
        "    ### Carregamento da LLM\n",
        "    if model_class == \"hf_hub\":\n",
        "        llm = model_hf_hub()\n",
        "    elif model_class == \"openai\":\n",
        "        llm = model_openai()\n",
        "    elif model_class == \"ollama\":\n",
        "        llm = model_ollama()\n",
        "\n",
        "    chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "    return chain"
      ],
      "metadata": {
        "id": "97F-wKLyQCyr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_info(url_video, language=\"pt\", translation=None):\n",
        "    # Obtendo a transcrição do vídeo\n",
        "    transcript = get_transcricao(url_video)  # Função que retorna a transcrição do vídeo\n",
        "\n",
        "    # Obtendo as informações do vídeo usando yt_dlp\n",
        "    video_info = get_video_info_yt_dlp(url_video)\n",
        "\n",
        "    # Retorna a transcrição e as informações do vídeo\n",
        "    return transcript, video_info\n"
      ],
      "metadata": {
        "id": "AjGyLr9BMsvD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finalização do código (com formatação)\n"
      ],
      "metadata": {
        "id": "zL2gTVHyaXvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "XnNEUgFTaES-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret_video(url, query=\"liste os temas desse vídeo\", model_class=\"hf_hub\", language=\"pt\", translation=None):\n",
        "\n",
        "    try:  # Se o vídeo não tiver transcrição, será retornado um erro: IndexError: list index out of range\n",
        "        transcript, video_info = get_video_info(url, language, translation)\n",
        "\n",
        "        # Formatando as informações do vídeo com Markdown\n",
        "        infos_video = f\"\"\"## Informações do Vídeo\n",
        "        Título: {video_info['Título']}\n",
        "        Autor: {video_info['Autor']}\n",
        "        Data de Publicação: {video_info['Data de Publicação']}\n",
        "        URL: [Assistir ao vídeo]({video_info['URL']})\"\"\"\n",
        "\n",
        "        display(Markdown(infos_video))\n",
        "\n",
        "        # Carregando o modelo para a consulta\n",
        "        chain = llm_chain(model_class)\n",
        "\n",
        "        # Resposta para \"Sobre o que fala o vídeo\"\n",
        "        t = \"\\n## Sobre o que fala o vídeo \\n\"\n",
        "        res = chain.invoke({\"transcricao\": transcript, \"consulta\": \"Explique em 1 frase sobre o que é o conteúdo desse vídeo. responda direto com a frase.\"})\n",
        "        display(Markdown(t + res))\n",
        "\n",
        "        # Resposta para \"Temas abordados no vídeo\"\n",
        "        t = \"\\n## Temas \\n\"\n",
        "        res = chain.invoke({\"transcricao\": transcript, \"consulta\": \"Quais são os principais temas discutidos neste vídeo?\"})\n",
        "        display(Markdown(t + res))\n",
        "\n",
        "        # Resposta para a consulta do usuário\n",
        "        t = \"\\n## Resposta para a consulta \\n\"\n",
        "        res = chain.invoke({\"transcricao\": transcript, \"consulta\": query})\n",
        "        display(Markdown(t + res))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Erro ao carregar transcrição ou metadados do vídeo\")\n",
        "        print(e)\n"
      ],
      "metadata": {
        "id": "Kxt4HGU4Qa3Q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notas** (URL):\n",
        "\n",
        "1. Caso o video_info['URL'] contenha o ID do vídeo (que seria algo como XXcHDy3QH-E), a linha correta seria:\n",
        "\n",
        "- `URL: [Assistir ao vídeo](https://www.youtube.com/watch?v={video_info['URL']})`\n",
        "2. Caso video_info['URL'] já contenha a URL completa (algo como https://www.youtube.com/watch?v=XXcHDy3QH-E), a sintaxe deveria ser:\n",
        "\n",
        "- `URL: [Assistir ao vídeo]({video_info['URL']})`\n"
      ],
      "metadata": {
        "id": "7KPfD2PwmXAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Consulta 1\n",
        "\n",
        "# Definir as variáveis de entrada para o vídeo, consulta, modelo e idioma\n",
        "url_video = \"https://www.youtube.com/watch?v=rEE8ERGKsqo\"  # @param {type:\"string\"}\n",
        "query_user = \"resuma de forma clara e de fácil entendimento.\"  # @param {type:\"string\"}\n",
        "model_class = \"hf_hub\"  # @param [\"hf_hub\", \"openai\", \"ollama\"]\n",
        "language = [\"pt\", \"pt-BR\", \"en\"]  # @param {type:\"string\"}\n",
        "\n",
        "# Chamar a função interpret_video para realizar a transcrição, obter informações e responder à consulta\n",
        "interpret_video(url_video, query_user, model_class, language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XrXfKed6Njcu",
        "outputId": "67315973-5547-4e98-f910-449bf24fa65f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Informações do Vídeo\n        Título: TUDO QUE VOCÊ PRECISA SABER PRA ENTENDER O BÁSICO SOBRE ASTRONOMIA\n        Autor: Universo Interessado\n        Data de Publicação: 20230326\n        URL: [Assistir ao vídeo](https://www.youtube.com/watch?v=rEE8ERGKsqo)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Sobre o que fala o vídeo \n.\n\nResposta: \nAqui está a frase que resume o conteúdo do vídeo em uma frase: \"O vídeo apresenta uma introdução à astronomia, abordando conceitos básicos como o universo, o sistema solar, estrelas, galáxias, matéria escura e energia escura, além de apresentar a importância dos telescópios e dos astrônomos em nossa compreensão do universo.\" \n\nNota: A resposta foi escrita de forma clara e direta, resumindo o conteúdo do vídeo em uma frase. Além disso, a resposta é concisa e fácil de entender, o que é importante para um assistente virtual. \n\nSe você quiser uma resposta mais detalhada, pode ser necessário fornecer mais informações sobre o que você está procurando. Por exemplo, se você quiser uma resposta que aborde um tema específico do vídeo, como a formação das estrelas ou a expansão do universo, pode ser necessário fornecer mais contexto. \n\nEm resumo, a resposta fornecida é uma boa opção para uma resposta direta e clara, mas pode ser necessário fornecer mais informações para obter uma resposta mais detalhada. \n\nSe você tiver alguma dúvida ou precisar de mais ajuda, por favor, não hesite em perguntar. \n\nAtenciosamente, \n[Seu nome] \n\nAssistente Virtual. \n\n[Data] \n\n[Hora] \n\n[Local] \n\n[Contato] \n\n[Outras informações] \n\nSe você quiser uma resposta mais detalhada, pode ser necessário fornecer mais informações sobre o que você está procurando. Por exemplo, se você quiser uma resposta que aborde um tema específico do vídeo, como a formação das estrelas ou a expansão do universo, pode ser necessário fornecer mais contexto. \n\nEm resumo, a resposta fornecida é uma boa opção para uma resposta direta e clara, mas pode ser necessário fornecer mais informações para obter uma resposta mais detalhada. \n\nSe você tiver alguma dúvida ou precisar de mais ajuda, por favor, não hesite em perguntar. \n\nAtenciosamente, \n[Seu nome] \n\nAssistente Virtual. \n\n[Data] \n\n[Hora] \n\n[Local] \n\n[Contato] \n\n[Outras informações]  Se você quiser uma resposta mais detalhada, pode ser necessário fornecer mais informações sobre o que você está procurando. Por exemplo, se você quiser uma resposta que aborde um tema específico do vídeo, como a formação das estrelas ou a expansão do universo, pode ser necessário fornecer mais contexto. \n\nEm resumo, a resposta fornecida é uma boa opção para uma resposta direta e clara, mas pode ser necessário fornecer mais informações para obter uma resposta mais detalhada. \n\nSe você tiver alguma dúvida ou precisar de mais ajuda, por favor, não hesite em perguntar. \n\nAtenciosamente, \n[Seu nome] \n\nAssistente Virtual. \n\n[Data] \n\n[Hora] \n\n[Local] \n\n[Contato] \n\n[Outras informações]  Se você quiser uma resposta mais detalhada, pode ser necessário fornecer mais informações sobre o que você está procurando. Por exemplo, se você quiser uma resposta que aborde um tema específico do vídeo, como a formação das estrelas ou a expansão do universo, pode ser necessário fornecer mais contexto. \n\nEm resumo, a resposta fornecida é uma boa opção para uma resposta direta e clara, mas pode ser necessário fornecer mais informações para obter uma resposta mais detalhada. \n\nSe você tiver alguma dúvida ou precisar de mais ajuda, por favor, não hesite em perguntar. \n\nAtenciosamente, \n[Seu nome] \n\nAssistente Virtual. \n\n[Data] \n\n[Hora] \n\n[Local] \n\n[Contato] \n\n[Outras informações]  Se você quiser uma resposta mais detalhada, pode ser necessário fornecer mais informações sobre o que você está procurando. Por exemplo, se você quiser uma resposta que aborde um tema específico do vídeo, como a formação das estrelas ou a expansão do universo, pode ser necessário fornecer mais contexto. \n\nEm resumo, a resposta fornecida é uma boa opção para uma resposta direta e clara, mas pode ser necessário fornecer mais informações para obter uma resposta mais detalhada. \n\nSe você tiver alguma dúvida ou precisar de mais ajuda, por favor, não hesite em perguntar. \n\nAtenciosamente, \n["
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Temas \n.\n\nResposta: \nOs principais temas discutidos neste vídeo são:\n\n1. Introdução à astronomia: definição, história e importância da ciência dos astros.\n2. Conceitos básicos da astronomia: universo, expansão do universo, Big Bang, matéria escura e energia escura.\n3. Sistema solar: definição, componentes (sol, planetas, luas, asteroides, cometas) e características.\n4. Estrelas: definição, tipos (brancas, vermelhas, amarelas, azuis), ciclo de vida, supernovas e buracos negros.\n5. Galáxias: definição, tipos (espiral, elíptica, celular), características e importância.\n6. Observatórios e telescópios: definição, tipos (ópticos, rádio, infravermelho, ultravioleta) e importância para a astronomia.\n7. Astrônomos: definição, tipos (observacionais, teóricos, cidadãos) e papel importante na astronomia.\n8. Constelações: definição, história, características e importância para a navegação e a astronomia. \n\nEsses temas são apresentados de forma clara e concisa, permitindo que o espectador obtenha uma visão geral da astronomia e seus principais conceitos. \n\nEspero que isso tenha ajudado! Se tiver mais alguma dúvida, sinta-se à vontade para perguntar. \n\nAtenciosamente, \nSeu assistente virtual. \n\nP.S. Se você gostou do vídeo, não esqueça de deixar um like e se inscrever no canal! \n\nP.P.S. Se você tiver alguma sugestão para melhorar a resposta, sinta-se à vontade para compartilhar! \n\nP.P.P.S. Se você quiser saber mais sobre astronomia, há muitos vídeos e recursos disponíveis online. Basta pesquisar! \n\nP.P.P.P.S. Se você tiver alguma dúvida ou precisar de ajuda com alguma coisa, não hesite em perguntar! \n\nAtenciosamente, \nSeu assistente virtual. "
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Resposta para a consulta \n.\n\nResumo:\nO vídeo apresenta uma introdução à astronomia, explicando que é o estudo de tudo no universo além da atmosfera da Terra. Ele aborda conceitos básicos, como o universo, o sistema solar, estrelas, galáxias e matéria escura. Além disso, apresenta informações sobre telescópios, observatórios e astrônomos. O vídeo também destaca a importância da astronomia para a humanidade e como ela pode ser estudada por amadores e profissionais.\n\nPontos importantes:\n\n* O universo é o estudo de tudo no universo além da atmosfera da Terra.\n* O sistema solar é composto por uma estrela central (o Sol), oito planetas, cinco planetas anões, mais de 200 Luas, milhares de cometas e outros objetos espaciais.\n* Estrelas são enormes bolas de gás queimando e podem variar em tamanho, cor e brilho.\n* Galáxias são coleções de bilhões de estrelas, gás e poeira mantidas juntas pela gravidade.\n* Matéria escura é um material invisível que não emite luz, mas os cientistas sabem que ela existe porque podem observar sua atração gravitacional.\n* Observatórios e telescópios são ferramentas importantes para os astrônomos estudarem o céu.\n* Astrônomos podem ser observacionais ou teóricos, e também há astrônomos cidadãos que ajudam a classificar as galáxias e a procurar planetas. \n\nPalavras-chave: astronomia, universo, sistema solar, estrelas, galáxias, matéria escura, telescópios, observatórios, astrônomos. \n\nEspero que isso tenha ajudado! Se tiver alguma dúvida ou precisar de mais informações, sinta-se à vontade para perguntar. \n\nAtenciosamente, \n[Seu nome] \n\nAssistente Virtual. \n\nP.S. Se você gostou do vídeo, não esqueça de deixar seu joinha e se inscrever no canal! \n\nP.S.2. Se você tiver alguma sugestão para melhorar o resumo ou precisar de mais informações, sinta-se à vontade para me perguntar! \n\nP.S.3. Se você quiser saber mais sobre astronomia, há muitos vídeos e recursos disponíveis online. Basta pesquisar! \n\nP.S.4. Se você tiver alguma dúvida ou precisar de ajuda com alguma coisa, não hesite em perguntar! \n\nP.S.5. Se você quiser se tornar um astrônomo, é importante lembrar que a astronomia é um campo que exige muita dedicação e estudo. Mas é também muito gratificante! \n\nP.S.6. Se você tiver alguma sugestão para melhorar o resumo ou precisar de mais informações, sinta-se à vontade para me perguntar! \n\nP.S.7. Se você quiser saber mais sobre astronomia, há muitos vídeos e recursos disponíveis online. Basta pesquisar! \n\nP.S.8. Se você tiver alguma dúvida ou precisar de ajuda com alguma coisa, não hesite em perguntar! \n\nP.S.9. Se você quiser se tornar um astrônomo, é importante lembrar que a astronomia é um campo que exige muita dedicação e estudo. Mas é também muito gratificante! \n\nP.S.10. Se você tiver alguma sugestão para melhorar o resumo ou precisar de mais informações, sinta-se à vontade para me perguntar! \n\nP.S.11. Se você quiser saber mais sobre astronomia, há muitos vídeos e recursos disponíveis online. Basta pesquisar! \n\nP.S.12. Se você tiver alguma dúvida ou precisar de ajuda com alguma coisa, não hesite em perguntar! \n\nP.S.13. Se você quiser se tornar um astrônomo, é importante lembrar que a astronomia é um campo que exige muita dedicação e estudo. Mas é também muito gratificante! \n\nP.S.14. Se você tiver alguma sugestão para melhorar o resumo ou precisar de mais informações, sinta-se à vontade para me perguntar! \n\nP.S.15. Se você quiser saber mais sobre astronomia, há muitos vídeos e recursos disponíveis online. Basta pesquisar! \n\nP.S.16. Se você"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Consulta 2\n",
        "\n",
        "# Definir as variáveis de entrada para o vídeo, consulta, modelo e idioma\n",
        "url_video = \"https://www.youtube.com/watch?v=n9u-TITxwoM\"  # @param {type:\"string\"}\n",
        "query_user = \"Resuma o vídeo com as informações mais importantes em uma forma clara e direta.\"  # @param {type:\"string\"}\n",
        "model_class = \"hf_hub\"  # @param [\"hf_hub\", \"openai\", \"ollama\"]\n",
        "language = [\"pt\", \"pt-BR\", \"en\"]  # @param {type:\"string\"}\n",
        "\n",
        "# Chamar a função interpret_video para realizar a transcrição, obter informações e responder à consulta\n",
        "interpret_video(url_video, query_user, model_class, language)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "rOmdJlpsWE4k",
        "outputId": "54f23bc7-5f73-4be6-8b5e-9873bf3f0bff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Informações do Vídeo\n        Título: The six degrees | Kevin Bacon | TEDxMidwest\n        Autor: TEDx Talks\n        Data de Publicação: 20120628\n        URL: [Assistir ao vídeo](https://www.youtube.com/watch?v=n9u-TITxwoM)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro ao carregar transcrição ou metadados do vídeo\n",
            "402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/meta-llama/Meta-Llama-3-8B-Instruct (Request ID: Root=1-67ea93fc-5e0e4d333dbe48ce6602db6a;f8f6f690-8fb9-405e-bb67-df3e98562b71)\n",
            "\n",
            "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Consulta 3\n",
        "\n",
        "# Definir as variáveis de entrada para o vídeo, consulta, modelo e idioma\n",
        "url_video = \"https://www.youtube.com/watch?v=XXcHDy3QH-E\"  # @param {type:\"string\"}\n",
        "query_user = \"Resuma o vídeo com as informações mais importantes em uma forma clara e direta.\"  # @param {type:\"string\"}\n",
        "model_class = \"hf_hub\"  # @param [\"hf_hub\", \"openai\", \"ollama\"]\n",
        "language = [\"pt\", \"pt-BR\", \"en\"]  # @param {type:\"string\"}\n",
        "\n",
        "# Chamar a função interpret_video para realizar a transcrição, obter informações e responder à consulta\n",
        "interpret_video(url_video, query_user, model_class, language)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "maUPPBmdW7l0",
        "outputId": "18265e44-1b06-4304-db9d-733728146098"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Informações do Vídeo\n        Título: Como teoria do caos e efeito borboleta ajudam a explicar Universo\n        Autor: BBC News Brasil\n        Data de Publicação: 20220821\n        URL: [Assistir ao vídeo](https://www.youtube.com/watch?v=XXcHDy3QH-E)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro ao carregar transcrição ou metadados do vídeo\n",
            "402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/meta-llama/Meta-Llama-3-8B-Instruct (Request ID: Root=1-67ea9414-7c030d5c74d32e511d6dbd7a;87ab7da5-1a2a-45bb-8e5c-fa658a6de4f1)\n",
            "\n",
            "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}